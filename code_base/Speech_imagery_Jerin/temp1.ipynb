{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio, numpy as np, scipy\n",
    "import os, re, random,concurrent.futures, time, copy\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = {\"Long_words\": \"/home/tusharsingh/DATAs/speech_EEG/Long_words\",\n",
    "        \"Short_Long_words\": \"/home/tusharsingh/DATAs/speech_EEG/Short_Long_words\",\n",
    "        \"Short_words\": \"/home/tusharsingh/DATAs/speech_EEG/Short_words\",\n",
    "        \"Vowels\": \"/home/tusharsingh/DATAs/speech_EEG/Vowels\"}\n",
    "\n",
    "Labels = {\"Long_words\": {1: \"cooperate\",2: \"independent\"},\n",
    "        \"Short_Long_words\": {1:\"cooperate\",2:\"in\"},\n",
    "        \"Short_words\": {1:\"out\",2:\"in\",3:\"up\"},\n",
    "        \"Vowels\": {1:\"a\",2:\"i\",3:\"u\"}}\n",
    "\n",
    "words = {\"Long_words\": {\"cooperate\" : 0,\"independent\" : 1},\n",
    "        \"Short_Long_words\": {\"cooperate\" : 0,\"in\" : 1},\n",
    "        \"Short_words\": {\"out\" : 0,\"in\" : 1,\"up\" : 2},\n",
    "        \"Vowels\": {\"a\" : 0, \"i\": 1, \"u\": 2}}\n",
    "\n",
    "eeg_image_folder_path = {\"Long_words\": \"/home/tusharsingh/DATAs/speech_EEG/EEG_image/Long_words\",\n",
    "        \"Short_Long_words\": \"/home/tusharsingh/DATAs/speech_EEG/EEG_image/Short_Long_words\",\n",
    "        \"Short_words\": \"/home/tusharsingh/DATAs/speech_EEG/EEG_image/Short_words\",\n",
    "        \"Vowels\": \"/home/tusharsingh/DATAs/speech_EEG/EEG_image/Vowels\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads EEGs from the path given \n",
    "def load_EEG(path, words):\n",
    "    eeg = []\n",
    "    labels = []\n",
    "    patient_id = []\n",
    "    name = []\n",
    "    for subject in os.scandir(path):\n",
    "        if subject.is_file() and subject.name.endswith('.mat'):\n",
    "            mat = sio.loadmat(subject.path)['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
    "            for label in range(mat.shape[0]):\n",
    "                for j in range(mat[label].shape[0]):\n",
    "                    eeg.append(mat[label][j][:64,:])\n",
    "                    labels.append(words[label + 1])\n",
    "                    patient_id.append(int(re.search(\"[0-9]+\", subject.name).group(0)))\n",
    "                    name.append(f\"patient_{patient_id[-1]}_word_{labels[-1]}_trial_{j+1}\")\n",
    "    return [eeg,labels,patient_id, name]\n",
    "\n",
    "# return augmented_data with given window_size and stride\n",
    "def augmented_data(path, words, window_size = 256, stride = 64):\n",
    "    EEG, Labels, Patient_id, file_name = load_EEG(path, words)\n",
    "    X = []\n",
    "    Y = []\n",
    "    id = []\n",
    "    augmented_file_name = []\n",
    "    for eeg, label, patient_id, name in zip(EEG, Labels, Patient_id, file_name):\n",
    "        for start in range(0, eeg.shape[1] - window_size + 1, stride):\n",
    "            X.append(eeg[:,start: start + window_size])\n",
    "            Y.append(label)\n",
    "            id.append(patient_id)\n",
    "            augmented_file_name.append(f\"{name}_{start//stride + 1}\")\n",
    "\n",
    "    return [X, Y, id, augmented_file_name]\n",
    "\n",
    "\n",
    "# retrieves the MPC(Mean Phase Coherance) feature matrix for given EEG 64 channel\n",
    "def MPC(eeg):\n",
    "    channels = eeg.shape[0]\n",
    "    mpc_matrix = np.zeros((channels, channels), dtype = float)\n",
    "\n",
    "    def MPC_feature(i,j):\n",
    "        signal_a = np.unwrap(np.angle(scipy.signal.hilbert(eeg[i])))\n",
    "        signal_b = np.unwrap(np.angle(scipy.signal.hilbert(eeg[j])))\n",
    "        phase_diff = np.exp((signal_a - signal_b) * 1j)\n",
    "        return np.absolute(np.mean(phase_diff))\n",
    "        \n",
    "    for i in range(channels):\n",
    "        for j in range(channels):\n",
    "            if i <= j:\n",
    "                mpc_matrix[i, j] = MPC_feature(i,j)\n",
    "            else:\n",
    "                mpc_matrix[i, j] = mpc_matrix[j, i]\n",
    "    return mpc_matrix\n",
    "\n",
    "    \n",
    "# retrieves the MSC(Magnitude Phase Coherance) feature matrix for given EEG 64 channel\n",
    "def MSC(eeg):\n",
    "    channels = eeg.shape[0]\n",
    "    msc_matrix = np.zeros((channels, channels), dtype = float)\n",
    "        \n",
    "    for i in range(channels):\n",
    "        for j in range(channels):\n",
    "            if i <= j:\n",
    "                msc_matrix[i, j] = np.mean(scipy.signal.coherence(eeg[i], eeg[j], window = scipy.signal.windows.hamming(32), fs = 256)[1])\n",
    "            else:\n",
    "                msc_matrix[i, j] = msc_matrix[j, i]\n",
    "    return msc_matrix\n",
    "\n",
    "\n",
    "# alpha beta gamma filtering for every eeg electrode    \n",
    "def alpha_beta_gamma_extractor(eeg):\n",
    "    a = scipy.signal.butter(8, [8,13], 'bandpass', fs=256, output='sos')\n",
    "    b = scipy.signal.butter(8, [13,30], 'bandpass', fs=256, output='sos')\n",
    "    g = scipy.signal.butter(8, [30,70], 'bandpass', fs=256, output='sos')\n",
    "\n",
    "    alpha = np.zeros_like(eeg)\n",
    "    beta = np.zeros_like(eeg)\n",
    "    gamma = np.zeros_like(eeg)\n",
    "\n",
    "    for i in range(eeg.shape[0]):\n",
    "        alpha[i] = scipy.signal.sosfilt(a, eeg[i])\n",
    "        beta[i] = scipy.signal.sosfilt(b, eeg[i])\n",
    "        gamma[i] = scipy.signal.sosfilt(g, eeg[i])\n",
    "    \n",
    "    return [alpha, beta, gamma]\n",
    "\n",
    "\n",
    "# reutrn Image form of the eeg from alpha beta gamma bands and MPC and MSC feature matrix\n",
    "def EEG_Image(eeg, **kwargs):\n",
    "    eeg_channles = alpha_beta_gamma_extractor(eeg)\n",
    "    Image = np.zeros((eeg.shape[0],eeg.shape[0],3), dtype=float)\n",
    "    for i in range(3):\n",
    "        eeg_mpc = MPC(eeg_channles[i])\n",
    "        eeg_msc = MPC(eeg_channles[i])\n",
    "        n = eeg_mpc.shape[0]\n",
    "        for p in range(n):\n",
    "            for q in range(n):\n",
    "                if p < q:\n",
    "                    Image[p,q,i] = eeg_mpc[p,q]\n",
    "                elif p > q:\n",
    "                    Image[p,q,i] = eeg_msc[p,q]\n",
    "    return Image\n",
    "\n",
    "\n",
    "# it extracts eeg Image and writes it into given location with proper name\n",
    "def eeg_image_folder_maker(store_path, data, start, stop):\n",
    "    X, Y, id, file_name = data\n",
    "    for i in range(start,stop):\n",
    "        with open(f\"{store_path}/{file_name[i]}\", 'wb') as f:\n",
    "            np.save(f, EEG_Image(X[i]))\n",
    "            np.save(f, Y[i])\n",
    "            np.save(f, id[i])   \n",
    "\n",
    "\n",
    "# extracts EEG image data from folder with augmentation method and writes to new location in parllel way\n",
    "def parllel_feature_extracting(folder_name):\n",
    "    data = augmented_data(folder_path[folder_name], Labels[folder_name], 256, 64)\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        N = len(data[1])\n",
    "        cores = 40\n",
    "        per_core = N // cores\n",
    "        for i in range(0, N, per_core):\n",
    "            executor.submit(eeg_image_folder_maker, eeg_image_folder_path[folder_name], data, i, i + per_core)\n",
    "\n",
    "\n",
    "# returns particular patient's EEG image path and corresponding immagined word list\n",
    "def Patient_id_data(eeg_image_path, patient_id):\n",
    "    file_names = os.listdir(eeg_image_path)\n",
    "    X = [f\"{eeg_image_path}//{each}\" for each in file_names if each.startswith(f\"patient_{patient_id}\")]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, eeg_image_path, patient_id, words):\n",
    "        self.X = Patient_id_data(eeg_image_path, patient_id)\n",
    "        self.words = words\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with open(f\"{self.X[idx]}\", 'rb') as f:\n",
    "            image = np.load(f).transpose(2,0,1)\n",
    "            label = str(np.load(f))\n",
    "        return torch.tensor(image, dtype= torch.float), self.words[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EEG_Dataset(eeg_image_folder_path['Short_words'], 12, words['Short_words'])\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size = 10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to show a batch\n",
    "def show_landmarks_batch(sample_batched):\n",
    "    images_batch, word_batch = sample_batched\n",
    "    batch_size = len(images_batch)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        print(i, images_batch[i].shape,images_batch[i].dtype ,word_batch[i])\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch, sample_batched[0].size(),\n",
    "          len(sample_batched[1]))\n",
    "\n",
    "    # observe 4th batch and stop.\n",
    "    if i_batch == 3:\n",
    "        show_landmarks_batch(sample_batched)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = random_split(dataset, [0.85,0.15], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "\n",
    "data_dir = 'data/hymenoptera_data'\n",
    "EEG_image_datasets = {'train': train_dataset, 'valid': val_dataset}\n",
    "dataloaders = {x: DataLoader(EEG_image_datasets[x], batch_size=64,shuffle=True, num_workers=3) for x in ['train', 'valid']}\n",
    "dataset_sizes = {x: len(EEG_image_datasets[x]) for x in ['train', 'valid']}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, number_of_words):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.ResNet = models.resnet50(pretrained=True)\n",
    "        # for param in self.ResNet.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        self.fc1 = nn.Linear(self.ResNet.fc.in_features, 128)\n",
    "        self.ResNet.fc = nn.Identity()\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, number_of_words)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ResNet(x)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.functional.dropout(x, 0.3)\n",
    "        x = self.fc2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.functional.dropout(x, 0.3)\n",
    "        x = self.fc3(x)\n",
    "        x = nn.functional.softmax(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork(3).to(device=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 250, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if not epoch % 50:\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                # print( loss.item(), outputs, labels,running_loss)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            if not epoch % 50:\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\\n')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler,num_epochs = 300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subject 2 long words Best val Acc: 0.613725\n",
    "\n",
    "subject 3 long words Best val Acc: 0.633333\n",
    "\n",
    "short long words subj 14 Best val Acc: 0.798039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEG_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbd897dc215af05216e0d3ffd601dd8704a57817202699d71919a44dbfb4a982"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
